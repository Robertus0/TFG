{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Seleccio GPUs visibles\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3,4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lT0DfCbyw54I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/detectron2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "from torchvision.transforms import Resize\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn as nn\n",
    "%cd /tf/detectron2\n",
    "import detectron2\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.data import DatasetCatalog\n",
    "from detectron2.data import transforms as T\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "from PIL import Image, ImageDraw\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import json\n",
    "from torchviz import make_dot\n",
    "import copy\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eBkFi3JlsLwt"
   },
   "outputs": [],
   "source": [
    "# xmin, ymin, xmax, ymax to xmin, ymin, w, h\n",
    "def xyxy_to_xywh(coordenadas, clamp=False):\n",
    "    if type(coordenadas) != type(torch.tensor(0)):\n",
    "        coordenadas = torch.tensor(coordenadas)\n",
    "    coordenadas = torch.stack((coordenadas[:, 0],\n",
    "                               coordenadas[:, 1],\n",
    "                               coordenadas[:, 2] - coordenadas[:, 0],\n",
    "                               coordenadas[:, 3] - coordenadas[:, 1]\n",
    "                               ), dim=1)\n",
    "    if clamp:\n",
    "        coordenadas = torch.clamp(coordenadas, min=0, max=1)\n",
    "    return coordenadas\n",
    "\n",
    "# xmin, ymin, w, h to xmin, ymin, xmax, ymax\n",
    "def xywh_to_xyxy(coordenadas, clamp=False):\n",
    "    if type(coordenadas) != type(torch.tensor(0)):\n",
    "        coordenadas = torch.tensor(coordenadas)\n",
    "    coordenadas = torch.stack((coordenadas[:, 0], \n",
    "                               coordenadas[:, 1], \n",
    "                               coordenadas[:, 0] + coordenadas[:, 2],\n",
    "                               coordenadas[:, 1] + coordenadas[:, 3]\n",
    "                               ), dim=1)\n",
    "    if clamp:\n",
    "        coordenadas = torch.clamp(coordenadas, min=0, max=1)    \n",
    "    return coordenadas\n",
    "\n",
    "# cx, cy, w, h to xmin, ymin, xmax, ymax\n",
    "def cxcywh_to_xyxy(coordenadas, clamp=False):\n",
    "    if type(coordenadas) != type(torch.tensor(0)):\n",
    "        coordenadas = torch.tensor(coordenadas)\n",
    "    coordenadas = torch.stack((coordenadas[:, 0] - coordenadas[:, 2] / 2,\n",
    "                               coordenadas[:, 1] - coordenadas[:, 3] / 2,\n",
    "                               coordenadas[:, 0] + coordenadas[:, 2] / 2,\n",
    "                               coordenadas[:, 1] + coordenadas[:, 3] / 2\n",
    "                               ), dim=1)\n",
    "    if clamp:\n",
    "        coordenadas = torch.clamp(coordenadas, min=0, max=1)    \n",
    "    return coordenadas\n",
    "\n",
    "# xmin, ymin, xmax, ymax to cx, cy, w, h\n",
    "def xyxy_to_cxcywh(coordenadas, clamp=False):\n",
    "    if type(coordenadas) != type(torch.tensor(0)):\n",
    "        coordenadas = torch.tensor(coordenadas)\n",
    "    coordenadas = torch.stack(((coordenadas[:, 0] + coordenadas[:, 2]) / 2,\n",
    "                               (coordenadas[:, 1] + coordenadas[:, 3]) / 2,\n",
    "                               coordenadas[:, 2] - coordenadas[:, 0],\n",
    "                               coordenadas[:, 3] - coordenadas[:, 1]\n",
    "                               ), dim=1)\n",
    "    if clamp:\n",
    "        coordenadas = torch.clamp(coordenadas, min=0, max=1)    \n",
    "    return coordenadas\n",
    "\n",
    "# cx, cy, w, h to xmin, ymin, w, h\n",
    "def cxcywh_to_xywh(coordenadas, clamp=False):\n",
    "    if type(coordenadas) != type(torch.tensor(0)):\n",
    "        coordenadas = torch.tensor(coordenadas)\n",
    "    coordenadas = torch.stack((coordenadas[:, 0] - coordenadas[:, 2] / 2,\n",
    "                               coordenadas[:, 1] - coordenadas[:, 3] / 2,\n",
    "                               coordenadas[:, 2],\n",
    "                               coordenadas[:, 3]\n",
    "                               ), dim=1)\n",
    "    if clamp:\n",
    "        coordenadas = torch.clamp(coordenadas, min=0, max=1)    \n",
    "    return coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xPUzfM9-xFKz"
   },
   "outputs": [],
   "source": [
    "class PoolDetectionModel(nn.Module):\n",
    "    def __init__(self, num_classes, num_predictions = 100):\n",
    "        super(PoolDetectionModel, self).__init__()\n",
    "        \n",
    "        # Cargamos el modelo pre-entrenado\n",
    "        self.model = torch.hub.load('facebookresearch/detr:main', 'detr_resnet50', pretrained=True)\n",
    "\n",
    "        # Cambiamos el número de clases de salida\n",
    "        hidden_dim = self.model.transformer.d_model\n",
    "        self.model.num_classes = num_classes\n",
    "        self.model.class_embed = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "#         if num_predictions != False:\n",
    "          # Cambiamos el número predicciones\n",
    "#         num_query = self.model.transformer.d_model\n",
    "#         self.model.query_embed = nn.Sequential(nn.Embedding(num_predictions, num_query),\n",
    "#                                                  nn.Sigmoid()\n",
    "#                                                 )\n",
    "                \n",
    "    def forward(self, x):\n",
    "        # Pasamos las imágenes por el modelo pre-entrenado\n",
    "        outputs = self.model(x)\n",
    "        \n",
    "        # Obtenemos las cajas y las etiquetas de las predicciones\n",
    "        outputs['pred_logits'] = torch.sigmoid(outputs['pred_logits'])\n",
    "        \n",
    "        # Devolvemos las cajas y las etiquetas\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def declarar_modelo(paths, paramaters, Load_model = False):\n",
    "    # Calculate current number of test\n",
    "    current_test = get_current_test(paths[\"tests\"])\n",
    "    if Load_model:\n",
    "        # Load model\n",
    "        model = PoolDetectionModel(num_classes=paramaters[\"num_classes\"], num_predictions = paramaters[\"num_predictions\"])\n",
    "        # Path to current test\n",
    "        path_current_test = f'{paths[\"tests\"]}test {current_test}/'\n",
    "        paths[\"test\"] = path_current_test\n",
    "        # Calculate current epoch in test\n",
    "        current_epoch = get_current_epoch(path_current_test)\n",
    "        # Load model parameters\n",
    "        model = torch.load(f'{path_current_test}model_{current_epoch}.pt')\n",
    "        # Get previus losses\n",
    "        with open(f\"{path_current_test}model_loss_{current_epoch}.json\", 'r') as f:\n",
    "            train_loss = json.load(f)\n",
    "        with open(f\"{path_current_test}parameters.json\", 'r') as f:\n",
    "            paramaters = json.load(f)\n",
    "        paramaters[\"current_epoch\"] = current_epoch+1\n",
    "        print(f\"Load model {path_current_test}model_{current_epoch}.pt\")\n",
    "        print(f\"Load parameters {paramaters}\")\n",
    "    else:\n",
    "        # Create list of losses\n",
    "        train_loss = []\n",
    "        # Load model\n",
    "        model = PoolDetectionModel(num_classes=paramaters[\"num_classes\"])#, num_predictions = paramaters[\"num_predictions\"])\n",
    "        # Path to new test\n",
    "        path_current_test = f'{paths[\"tests\"]}test {current_test+1}/'\n",
    "        # Create directori of the new test\n",
    "        os.makedirs(path_current_test)\n",
    "        # Save parameters\n",
    "        with open(f\"{path_current_test}parameters.json\", 'w') as f:\n",
    "            json.dump(paramaters, f)\n",
    "        paths[\"test\"] = path_current_test\n",
    "        paramaters[\"current_epoch\"] = 1\n",
    "        print(\"New Model\")\n",
    "        print(path_current_test)\n",
    "        print(f\"Parameters {paramaters}\")\n",
    "    return model, paramaters, train_loss\n",
    "\n",
    "def get_current_epoch(path):\n",
    "    list_names = os.listdir(path)\n",
    "    list_names = [int(namefile[6:-3]) for namefile in list_names if namefile.endswith(\".pt\")]\n",
    "    return max(list_names)\n",
    "\n",
    "def get_current_test(path):\n",
    "    list_tests = sorted(os.listdir(path))\n",
    "    list_tests.pop(0)\n",
    "    list_tests = [int(namefile[5:]) for namefile in list_tests]\n",
    "    return max(list_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QnB9AG1tvm8G"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    images = []\n",
    "    targets = []\n",
    "    # Define the normalization transform\n",
    "    resize = transforms.Resize(new_size, antialias=None)\n",
    "    normalize = transforms.Normalize(mean=[0.53016539, 0.48067732, 0.410102], std=[0.25151319, 0.2374013, 0.23417556])\n",
    "    transform = transforms.Compose([transforms.ToTensor(), resize, normalize])\n",
    "    for sample in batch:\n",
    "        image = Image.open(sample['file_name']).convert('RGB')\n",
    "        width, height = image.size\n",
    "        # Transformar la imagen\n",
    "        image = transform(image)\n",
    "        # Adaptar las anotaciones\n",
    "        annotations = copy.deepcopy(sample['annotations'])\n",
    "        for ann in annotations:\n",
    "            bbox = ann['bbox']\n",
    "            x_original, y_original, w_original, h_original = bbox\n",
    "            x_new = x_original / width #* new_size[1]\n",
    "            y_new = y_original / height #* new_size[0]\n",
    "            w_new = w_original / width #* new_size[1]\n",
    "            h_new = h_original / height #* new_size[0]\n",
    "            ann['bbox'] = [x_new, y_new, w_new, h_new]\n",
    "#             print(ann['bbox'])\n",
    "        \n",
    "        # Añadir la imagen y las anotaciones a la lista\n",
    "        if len(annotations) != 0:\n",
    "            images.append(image)\n",
    "            targets.append({'boxes': [ann['bbox'] for ann in annotations], 'labels': [1 for ann in annotations], \"image_id\": sample['image_id']})\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-ZWrtbXfxAK2"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, data_loader, device, losses, epochs, current_epoch):\n",
    "    model.train()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"class_embed\" not in name and \"bbox_embed\" not in name:\n",
    "            param.requires_grad = False\n",
    "        else:\n",
    "            print(\"No congelando:\", name)\n",
    "    for epoch in range(current_epoch, epochs):\n",
    "        print(\"\\nEpoch:\", epoch, \"\\n\")\n",
    "        loss_epoch = []\n",
    "        for images_, targets_ in tqdm(data_loader):\n",
    "            images = copy.deepcopy(images_)\n",
    "            targets = copy.deepcopy(targets_)\n",
    "            images = [image.to(device) for image in images]\n",
    "            targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = hungarian_loss_2(output, targets)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 0.1, norm_type = 2)\n",
    "#             make_dot(loss, params=dict(model.named_parameters()), show_attrs=True, show_saved=True).render('graph', format='pdf', directory='/tf')\n",
    "#             return\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            loss = loss.item()/len(images)\n",
    "            loss_epoch.append(loss)\n",
    "#           if len(losses) > 2 and abs(losses[-1] - losses[-2]) < 10**-6:\n",
    "#             return\n",
    "        losses = losses+loss_epoch\n",
    "        torch.save(model, f\"{paths['test']}model_{epoch}.pt\")\n",
    "        with open(f\"{paths['test']}model_loss_{epoch}.json\", 'w') as f:\n",
    "            json.dump(losses, f)\n",
    "        paramaters[\"current_epoch\"] = epoch+1\n",
    "        print(\" Model saved\")\n",
    "        print(\"loss:\", loss)\n",
    "        print(cxcywh_to_xyxy(output[\"pred_boxes\"][0])[0])\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hungarian_loss_2(outputs, targets):\n",
    "    # reorder outputs and targets based in the hungarian algorithm without breaking the computation graph\n",
    "    # outputs are the predicted bounding boxes and labels in the format ([batch_size, num_queries, 4], [batch_size, num_queries, num_classes])\n",
    "    # targets are the ground truth bounding boxes and labels in the format [{'boxes': [x1, y1, x2, y2], 'labels': [0, 1, 2, 3]}, {'boxes': [x1, y1, x2, y2], 'labels': [0, 1, 2, 3]}]\n",
    "    # the loss is calculated as the sum of the l1 loss, the iou loss and the classification loss    \n",
    "    # convert the targets to the same format as the outputs\n",
    "    true_boxes = [torch.tensor(target['boxes'], dtype=torch.float32).to(device) for target in targets]\n",
    "    true_labels = [torch.tensor(target['labels'], dtype=torch.float32).to(device) for target in targets]\n",
    "    \n",
    "    l1 = 0\n",
    "    iou = 0\n",
    "    classification = 0\n",
    "    \n",
    "    for n in range(len(true_boxes)):\n",
    "        row_ind, col_ind = hungarian((xywh_to_xyxy(true_boxes[n]), true_labels[n]), (cxcywh_to_xyxy(outputs[\"pred_boxes\"][n]), outputs['pred_logits'][n]))\n",
    "        # Calculate the losses\n",
    "        p_boxes = cxcywh_to_xyxy(outputs[\"pred_boxes\"][n][row_ind])\n",
    "        t_boxes = xywh_to_xyxy(true_boxes[n][col_ind])\n",
    "        mask_row = torch.ones(outputs['pred_logits'][n].shape, dtype=torch.bool)\n",
    "        mask_row[row_ind] = False\n",
    "        p_label = torch.cat((outputs['pred_logits'][n][row_ind], outputs['pred_logits'][n][mask_row].unsqueeze(1)), 0)\n",
    "        t_label = torch.cat((true_labels[n][col_ind].unsqueeze(1), torch.zeros(p_label.shape[0]-len(col_ind)).to(device).unsqueeze(1)))\n",
    "        l1 = l1 + torch.nn.functional.l1_loss(p_boxes, t_boxes)\n",
    "        # iou = torchvision.ops.complete_box_iou_loss(pred_boxes, true_boxes, reduction = \"mean\")\n",
    "#         print(cxcywh_to_xyxy(outputs[\"pred_boxes\"][n][row_ind])[0], xywh_to_xyxy(true_boxes[n][col_ind])[0])\n",
    "        iou = iou + torchvision.ops.generalized_box_iou_loss(p_boxes, t_boxes, reduction = \"mean\")\n",
    "        classification = classification + torch.nn.functional.binary_cross_entropy(p_label, t_label)\n",
    "\n",
    "    # Combinamos las losses\n",
    "    l1_weight, iou_weight, classification_weight = 5, 2, 2\n",
    "    loss = l1_weight * l1 + iou_weight * iou + classification_weight * classification    \n",
    "    return loss\n",
    "\n",
    "def hungarian(true, pred):\n",
    "    true_boxes, true_labels = true\n",
    "    boxes, labels = pred\n",
    "    \n",
    "    true_labels = true_labels.unsqueeze(1)\n",
    "    \n",
    "    # Calculamos el costo de emparejamiento entre las cajas predichas y verdaderas\n",
    "    cost_boxes = torch.cdist(boxes, true_boxes, p=1)\n",
    "    \n",
    "    # Calculamos el costo de emparejamiento entre las etiquetas predichas y verdaderas\n",
    "    cost_labels = torch.cdist(labels, true_labels, p=1)\n",
    "    \n",
    "    # Combinamos los costos\n",
    "    cost = cost_boxes + cost_labels\n",
    "    \n",
    "    # Resolvemos el problema de asignación lineal\n",
    "    row_ind, col_ind = linear_sum_assignment(cost.cpu().detach().numpy())\n",
    "    \n",
    "    return row_ind, col_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_memoria(batch):\n",
    "    images = []\n",
    "    targets = []\n",
    "    for sample in batch:\n",
    "        if sample[\"image_id\"] < len(list_images):\n",
    "            images.append(list_images[sample[\"image_id\"]-1])\n",
    "            targets.append(list_targets[sample[\"image_id\"]-1])\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cargar_dataset_memoria(dataset, batch_size):\n",
    "    images = []\n",
    "    targets = []\n",
    "    resize = transforms.Resize(new_size, antialias=None)\n",
    "    normalize = transforms.Normalize(mean=[0.53016539, 0.48067732, 0.410102], std=[0.25151319, 0.2374013, 0.23417556])\n",
    "    transform = transforms.Compose([transforms.ToTensor(), resize, normalize])\n",
    "    for sample in tqdm(dataset):\n",
    "        # Define the normalization transform\n",
    "        image = Image.open(sample['file_name']).convert('RGB')\n",
    "        width, height = image.size\n",
    "        # Transformar la imagen\n",
    "        image = transform(image)\n",
    "        # Adaptar las anotaciones\n",
    "        annotations = sample['annotations']\n",
    "        for ann in annotations:\n",
    "            bbox = ann['bbox']\n",
    "            x_original, y_original, w_original, h_original = bbox\n",
    "            x_new = x_original / width #* new_size[1]\n",
    "            y_new = y_original / height #* new_size[0]\n",
    "            w_new = w_original / width #* new_size[1]\n",
    "            h_new = h_original / height #* new_size[0]\n",
    "            ann['bbox'] = [x_new, y_new, w_new, h_new]\n",
    "        # Añadir la imagen y las anotaciones a la lista\n",
    "        if len(annotations) != 0:\n",
    "            images.append(image)\n",
    "            targets.append({'boxes': [ann['bbox'] for ann in annotations], 'labels': [1 for ann in annotations if ann['category_id'] == 0]})\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_detr_main\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model /tf/data/tmp/PoolsDS/Dataset improved 4/tests/test 58/model_299.pt\n",
      "Load parameters {'learning_rate': 0.0001, 'max_lr': 0.0001, 'momentum': 0.9, 'batch_size': 8, 'epochs': 500, 'num_classes': 1, 'num_predictions': 300, 'weight_decay': 0.0001, 'notes': '', 'current_epoch': 300}\n",
      "Comprobando device\n",
      "Utilizando : cuda\n"
     ]
    }
   ],
   "source": [
    "path_dataset = \"/tf/data/tmp/PoolsDS/Dataset improved 4/\"\n",
    "paths = {\"dataset\": f\"{path_dataset}\",\n",
    "         \"tests\": f\"{path_dataset}tests/\",\n",
    "         \"annotations_train\": f\"{path_dataset}train/_annotations.coco.json\",\n",
    "         \"annotations_test\": f\"{path_dataset}test/_annotations.coco.json\",\n",
    "         \"annotations_validation\": f\"{path_dataset}valid/_annotations.coco.json\",\n",
    "         \"images_train\": f\"{path_dataset}train/\",\n",
    "         \"images_test\": f\"{path_dataset}test/\",\n",
    "         \"images_validation\": f\"{path_dataset}valid/\"\n",
    "         }\n",
    "\n",
    "paramaters = {\"learning_rate\": 10**(-4),\n",
    "              \"max_lr\": 10**(-3),\n",
    "              \"momentum\": 0.9,\n",
    "              \"batch_size\": 4,\n",
    "              \"epochs\": 100, \n",
    "              \"num_classes\": 1,\n",
    "              \"num_predictions\": 100,\n",
    "              \"weight_decay\": 10**(-4)\n",
    "              }\n",
    "\n",
    "\n",
    "Load_model = True\n",
    "new_size = (700, 700)\n",
    "\n",
    "# Declarar el modelo \n",
    "model, paramaters, train_loss = declarar_modelo(paths, paramaters, Load_model = Load_model)\n",
    "\n",
    "# Declarar el optimizador\n",
    "# optimizer = optim.SGD(model.parameters(), lr=paramaters[\"learning_rate\"], momentum=paramaters[\"momentum\"])\n",
    "optimizer = optim.AdamW(model.parameters(), lr=paramaters[\"learning_rate\"], weight_decay=paramaters[\"weight_decay\"])\n",
    "\n",
    "# Declarar el scheduler\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=paramaters[\"learning_rate\"], max_lr=paramaters[\"max_lr\"], cycle_momentum=False)\n",
    "# scheduler = None\n",
    "print(\"Comprobando device\")\n",
    "# Declarar el dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Utilizando :\", device)\n",
    "\n",
    "# Mover el modelo y el DataLoader al dispositivo\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Cargar la instancia de COCO como un objeto Dataset\u001b[39;00m\n\u001b[1;32m      8\u001b[0m dataset_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpiscinas_entrenamiento\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDatasetCatalog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Obtener metadatos del dataset\u001b[39;00m\n\u001b[1;32m     11\u001b[0m metadata \u001b[38;5;241m=\u001b[39m MetadataCatalog\u001b[38;5;241m.\u001b[39mget(dataset_name)\n",
      "File \u001b[0;32m/tf/detectron2/detectron2/data/catalog.py:58\u001b[0m, in \u001b[0;36m_DatasetCatalog.get\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not registered! Available datasets are: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     55\u001b[0m             name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[1;32m     56\u001b[0m         )\n\u001b[1;32m     57\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tf/detectron2/detectron2/data/datasets/coco.py:500\u001b[0m, in \u001b[0;36mregister_coco_instances.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image_root, (\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)), image_root\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# 1. register a function which returns dicts\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m DatasetCatalog\u001b[38;5;241m.\u001b[39mregister(name, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mload_coco_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# 2. Optionally, add metadata about this dataset,\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;66;03m# since they might be useful in evaluation, visualization or logging\u001b[39;00m\n\u001b[1;32m    504\u001b[0m MetadataCatalog\u001b[38;5;241m.\u001b[39mget(name)\u001b[38;5;241m.\u001b[39mset(\n\u001b[1;32m    505\u001b[0m     json_file\u001b[38;5;241m=\u001b[39mjson_file, image_root\u001b[38;5;241m=\u001b[39mimage_root, evaluator_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoco\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetadata\n\u001b[1;32m    506\u001b[0m )\n",
      "File \u001b[0;32m/tf/detectron2/detectron2/data/datasets/coco.py:69\u001b[0m, in \u001b[0;36mload_coco_json\u001b[0;34m(json_file, image_root, dataset_name, extra_annotation_keys)\u001b[0m\n\u001b[1;32m     67\u001b[0m json_file \u001b[38;5;241m=\u001b[39m PathManager\u001b[38;5;241m.\u001b[39mget_local_path(json_file)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mredirect_stdout(io\u001b[38;5;241m.\u001b[39mStringIO()):\n\u001b[0;32m---> 69\u001b[0m     coco_api \u001b[38;5;241m=\u001b[39m \u001b[43mCOCO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timer\u001b[38;5;241m.\u001b[39mseconds() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     71\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m takes \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m seconds.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(json_file, timer\u001b[38;5;241m.\u001b[39mseconds()))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pycocotools/coco.py:86\u001b[0m, in \u001b[0;36mCOCO.__init__\u001b[0;34m(self, annotation_file)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDone (t=\u001b[39m\u001b[38;5;132;01m{:0.2f}\u001b[39;00m\u001b[38;5;124ms)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39m tic))\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m dataset\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pycocotools/coco.py:95\u001b[0m, in \u001b[0;36mCOCO.createIndex\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotations\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ann \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotations\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 95\u001b[0m         imgToAnns[\u001b[43mann\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m]\u001b[38;5;241m.\u001b[39mappend(ann)\n\u001b[1;32m     96\u001b[0m         anns[ann[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m ann\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DatasetCatalog.clear()\n",
    "MetadataCatalog.clear()\n",
    "\n",
    "print(\"Load data\")\n",
    "# Registrar instancia de COCO\n",
    "register_coco_instances(\"piscinas_entrenamiento\", {}, paths[\"annotations_train\"], paths[\"images_train\"])\n",
    "# Cargar la instancia de COCO como un objeto Dataset\n",
    "dataset_name = \"piscinas_entrenamiento\"\n",
    "dataset = DatasetCatalog.get(dataset_name)\n",
    "# Obtener metadatos del dataset\n",
    "metadata = MetadataCatalog.get(dataset_name)\n",
    "# Cargar datos a memoria\n",
    "print(\"Cargando datos en memoria\")\n",
    "list_images, list_targets = Cargar_dataset_memoria(dataset, paramaters[\"batch_size\"])\n",
    "# Declarar el DataLoader\n",
    "data_loader_train = DataLoader(dataset, batch_size=paramaters[\"batch_size\"], collate_fn=collate_fn_memoria, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_aumentation(batch):\n",
    "    images = []\n",
    "    targets = []\n",
    "    # Define the normalization transform\n",
    "    resize = transforms.Resize(new_size, antialias=None)\n",
    "    normalize = transforms.Normalize(mean=[0.53016539, 0.48067732, 0.410102], std=[0.25151319, 0.2374013, 0.23417556])\n",
    "    transform = transforms.Compose([transforms.ToTensor(), resize, normalize])\n",
    "    for sample in batch:\n",
    "        image = Image.open(sample['file_name']).convert('RGB')\n",
    "        width, height = image.size\n",
    "        # Transformar la imagen\n",
    "        image = transform(image)\n",
    "        # Adaptar las anotaciones\n",
    "        annotations = copy.deepcopy(sample['annotations'])\n",
    "        for ann in annotations:\n",
    "            bbox = ann['bbox']\n",
    "            x_original, y_original, w_original, h_original = bbox\n",
    "            x_new = x_original / width #* new_size[1]\n",
    "            y_new = y_original / height #* new_size[0]\n",
    "            w_new = w_original / width #* new_size[1]\n",
    "            h_new = h_original / height #* new_size[0]\n",
    "            ann['bbox'] = [x_new, y_new, w_new, h_new]\n",
    "#             print(ann['bbox'])\n",
    "        \n",
    "        # Añadir la imagen y las anotaciones a la lista\n",
    "        if len(annotations) != 0:\n",
    "            images.append(image)\n",
    "            targets.append({'boxes': [ann['bbox'] for ann in annotations], 'labels': [1 for ann in annotations if ann['category_id'] == 0]})\n",
    "    return images, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/22 15:22:52 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/22 15:22:52 d2.data.datasets.coco]: \u001b[0mLoaded 958 images in COCO format from /tf/data/tmp/PoolsDS/Dataset improved 3/valid/_annotations.coco.json\n"
     ]
    }
   ],
   "source": [
    "DatasetCatalog.clear()\n",
    "MetadataCatalog.clear()\n",
    "\n",
    "dataset_name = \"piscinas_valid\"\n",
    "# Registrar instancia de COCO\n",
    "register_coco_instances(dataset_name, {}, paths[\"annotations_validation\"], paths[\"images_validation\"])\n",
    "# Cargar la instancia de COCO como un objeto Dataset\n",
    "dataset = DatasetCatalog.get(dataset_name)\n",
    "# Obtener metadatos del dataset\n",
    "metadata = MetadataCatalog.get(dataset_name)\n",
    "# Declarar el DataLoader\n",
    "data_loader_validation = DataLoader(dataset, batch_size=paramaters[\"batch_size\"], collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "threshold = 0.9\n",
    "for images, targets in data_loader_validation:\n",
    "    images = [image.to(device) for image in images]\n",
    "    targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "    for n in range(len(images)):\n",
    "        image = images[n].cpu().numpy()\n",
    "        image = np.moveaxis(image, 0, -1)\n",
    "        fig, ax = plt.subplots()\n",
    "        for bounding_box in targets[n][\"boxes\"]:\n",
    "            x, y, w, h = bounding_box\n",
    "            x, y, w, h = x*new_size[0], y*new_size[1], w*new_size[0], h*new_size[1]\n",
    "            bb = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
    "            ax.add_patch(bb)\n",
    "        ax.imshow(image)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training begin\")\n",
    "train(model, optimizer, data_loader_train, device, train_loss, paramaters[\"epochs\"], paramaters[\"current_epoch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_test = 58\n",
    "current_epoch = 241\n",
    "path_current_test = f'{paths[\"tests\"]}test {current_test}/'\n",
    "with open(f\"{path_current_test}model_loss_{current_epoch}.json\", 'r') as f:\n",
    "    t_loss, v_loss = json.load(f)\n",
    "model = torch.load(f'{path_current_test}model_{current_epoch}.pt')\n",
    "with open(f\"{path_current_test}parameters.json\", 'r') as f:\n",
    "            paramaters = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4fD-6OPfTtuZ",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.0001, 'max_lr': 0.0001, 'momentum': 0.9, 'batch_size': 8, 'epochs': 500, 'num_classes': 1, 'num_predictions': 300, 'weight_decay': 0.0001, 'notes': ''}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(t_loss, label=\"train_loss\")\n",
    "plt.plot(v_loss, label=\"validation_loss\")\n",
    "plt.legend()\n",
    "print(paramaters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1974024965341434 1.1337168549497922 2.3311193514839355 216\n"
     ]
    }
   ],
   "source": [
    "indice = t_loss.index(min(t_loss))\n",
    "print(t_loss[indice], v_loss[indice], t_loss[indice] + v_loss[indice], indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2098281000163924 1.080046712193224 2.289874812209616 240\n"
     ]
    }
   ],
   "source": [
    "indice = v_loss.index(min(v_loss))\n",
    "print(t_loss[indice], v_loss[indice], t_loss[indice] + v_loss[indice], indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_eval(batch):\n",
    "    images = []\n",
    "    targets = []\n",
    "    images_originales = []\n",
    "    # Define the normalization transform\n",
    "    resize = transforms.Resize(new_size, antialias=None)\n",
    "    normalize = transforms.Normalize(mean=[0.53016539, 0.48067732, 0.410102], std=[0.25151319, 0.2374013, 0.23417556])\n",
    "    transform = transforms.Compose([transforms.ToTensor(), resize, normalize])\n",
    "    for sample in batch:\n",
    "        image_original = Image.open(sample['file_name']).convert('RGB')\n",
    "        width, height = image_original.size\n",
    "        # Transformar la imagen\n",
    "        image = transform(image_original)\n",
    "        # Adaptar las anotaciones\n",
    "        annotations = copy.deepcopy(sample['annotations'])\n",
    "        for ann in annotations:\n",
    "            bbox = ann['bbox']\n",
    "            x_original, y_original, w_original, h_original = bbox\n",
    "            x_new = x_original / width #* new_size[1]\n",
    "            y_new = y_original / height #* new_size[0]\n",
    "            w_new = w_original / width #* new_size[1]\n",
    "            h_new = h_original / height #* new_size[0]\n",
    "            ann['bbox'] = [x_new, y_new, w_new, h_new]\n",
    "#             print(ann['bbox'])\n",
    "        \n",
    "        # Añadir la imagen y las anotaciones a la lista\n",
    "        if len(annotations) != 0:\n",
    "            images.append(image)\n",
    "            images_originales.append(image_original)\n",
    "            targets.append({'boxes': [ann['bbox'] for ann in annotations], 'labels': [1 for ann in annotations], \"image_id\": sample['image_id']})\n",
    "    return images, targets, images_originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/29 18:58:15 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/29 18:58:15 d2.data.datasets.coco]: \u001b[0mLoaded 937 images in COCO format from /tf/data/tmp/PoolsDS/Dataset improved 4/test/_annotations.coco.json\n"
     ]
    }
   ],
   "source": [
    "DatasetCatalog.clear()\n",
    "MetadataCatalog.clear()\n",
    "\n",
    "# Registrar instancia de COCO\n",
    "register_coco_instances(\"piscinas_test\", {}, paths[\"annotations_test\"], paths[\"images_test\"])\n",
    "# Cargar la instancia de COCO como un objeto Dataset\n",
    "dataset_name = \"piscinas_test\"\n",
    "dataset_test = DatasetCatalog.get(dataset_name)\n",
    "# Obtener metadatos del dataset\n",
    "metadata = MetadataCatalog.get(dataset_name)\n",
    "# Declarar el DataLoader\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=paramaters[\"batch_size\"], collate_fn=collate_fn_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "threshold = 0.2\n",
    "for n_id, (images, targets, images_originales) in enumerate(data_loader_test):\n",
    "    images = [image.to(device) for image in images]\n",
    "    targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "    output = model(images)\n",
    "    for n in range(len(images)):\n",
    "        image = np.asarray(images_originales[n])\n",
    "#         image = np.moveaxis(image, 0, -1)\n",
    "        mask_1d = output[\"pred_logits\"][n] > threshold\n",
    "        mask = torch.cat((mask_1d, mask_1d, mask_1d, mask_1d), 1)\n",
    "        pred_boxes = cxcywh_to_xywh(output[\"pred_boxes\"][n][mask].reshape(-1, 4))\n",
    "        if pred_boxes.shape[0] > 0:\n",
    "            fig, ax = plt.subplots()\n",
    "            plt.axis('off')\n",
    "            n_preds = len(pred_boxes)\n",
    "            pred_boxes_xyxy = xywh_to_xyxy(pred_boxes)\n",
    "            indices = torchvision.ops.nms(pred_boxes_xyxy, output[\"pred_logits\"][n][mask_1d], 0.5) \n",
    "            pred_boxes = pred_boxes[indices]\n",
    "            print(\"boxes\", pred_boxes.shape[0], len(targets[n][\"boxes\"]))\n",
    "            print(n_id*8+n)\n",
    "            \n",
    "            for bounding_box in pred_boxes:\n",
    "                x, y, w, h = bounding_box.cpu().detach().numpy()\n",
    "                x, y, w, h = x*new_size[0], y*new_size[1], w*new_size[0], h*new_size[1]\n",
    "                bb = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor=\"r\", facecolor='none')\n",
    "                ax.add_patch(bb)\n",
    "            for bounding_box in targets[n][\"boxes\"]:\n",
    "                x, y, w, h = bounding_box\n",
    "                x, y, w, h = x*new_size[0], y*new_size[1], w*new_size[0], h*new_size[1]\n",
    "                bb = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='b', facecolor='none')\n",
    "                ax.add_patch(bb)\n",
    "            ax.imshow(image)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "images_id = [754]\n",
    "\n",
    "threshold = 0.1\n",
    "for n_id, (images, targets, images_originales) in enumerate(data_loader_test):\n",
    "    images = [image.to(device) for image in images]\n",
    "    targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "    output = model(images)\n",
    "    for n in range(len(images)):\n",
    "        image = np.asarray(images_originales[n])\n",
    "#         image = np.moveaxis(image, 0, -1)\n",
    "        mask_1d = output[\"pred_logits\"][n] > threshold\n",
    "        mask = torch.cat((mask_1d, mask_1d, mask_1d, mask_1d), 1)\n",
    "        pred_boxes = cxcywh_to_xywh(output[\"pred_boxes\"][n][mask].reshape(-1, 4))\n",
    "        if pred_boxes.shape[0] > 0:\n",
    "            fig, ax = plt.subplots()\n",
    "            plt.axis('off')\n",
    "            n_preds = len(pred_boxes)\n",
    "            pred_boxes_xyxy = xywh_to_xyxy(pred_boxes)\n",
    "            indices = torchvision.ops.nms(pred_boxes_xyxy, output[\"pred_logits\"][n][mask_1d], 0.5) \n",
    "            pred_boxes = pred_boxes[indices]\n",
    "            if n_id*8+n in images_id:\n",
    "                print(\"boxes\", pred_boxes.shape[0], len(targets[n][\"boxes\"]))\n",
    "                print(n_id*8+n)\n",
    "\n",
    "                for bounding_box in pred_boxes:\n",
    "                    x, y, w, h = bounding_box.cpu().detach().numpy()\n",
    "                    x, y, w, h = x*new_size[0], y*new_size[1], w*new_size[0], h*new_size[1]\n",
    "                    bb = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor=\"r\", facecolor='none')\n",
    "                    ax.add_patch(bb)\n",
    "                for bounding_box in targets[n][\"boxes\"]:\n",
    "                    x, y, w, h = bounding_box\n",
    "                    x, y, w, h = x*new_size[0], y*new_size[1], w*new_size[0], h*new_size[1]\n",
    "                    bb = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='b', facecolor='none')\n",
    "                    ax.add_patch(bb)\n",
    "                ax.imshow(image)\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/29 15:56:20 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/29 15:56:20 d2.data.datasets.coco]: \u001b[0mLoaded 937 images in COCO format from /tf/data/tmp/PoolsDS/Dataset improved 4/test/_annotations.coco.json\n"
     ]
    }
   ],
   "source": [
    "DatasetCatalog.clear()\n",
    "MetadataCatalog.clear()\n",
    "\n",
    "dataset_name = \"piscinas_test\"\n",
    "# Registrar instancia de COCO\n",
    "register_coco_instances(dataset_name, {}, paths[\"annotations_test\"], paths[\"images_test\"])\n",
    "# Cargar la instancia de COCO como un objeto Dataset\n",
    "dataset = DatasetCatalog.get(dataset_name)\n",
    "# Obtener metadatos del dataset\n",
    "metadata = MetadataCatalog.get(dataset_name)\n",
    "# Declarar el DataLoader\n",
    "data_loader_test = DataLoader(dataset, batch_size=paramaters[\"batch_size\"], collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/29 15:55:25 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/29 15:55:25 d2.data.datasets.coco]: \u001b[0mLoaded 958 images in COCO format from /tf/data/tmp/PoolsDS/Dataset improved 4/valid/_annotations.coco.json\n"
     ]
    }
   ],
   "source": [
    "# DatasetCatalog.clear()\n",
    "# MetadataCatalog.clear()\n",
    "\n",
    "dataset_name = \"piscinas_validation\"\n",
    "# Registrar instancia de COCO\n",
    "register_coco_instances(dataset_name, {}, paths[\"annotations_validation\"], paths[\"images_validation\"])\n",
    "# Cargar la instancia de COCO como un objeto Dataset\n",
    "dataset = DatasetCatalog.get(dataset_name)\n",
    "# Obtener metadatos del dataset\n",
    "metadata = MetadataCatalog.get(dataset_name)\n",
    "# Declarar el DataLoader\n",
    "data_loader_validation = DataLoader(dataset, batch_size=paramaters[\"batch_size\"], collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/29 15:55:27 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[06/29 15:55:27 d2.data.datasets.coco]: \u001b[0mLoaded 7655 images in COCO format from /tf/data/tmp/PoolsDS/Dataset improved 4/train/_annotations.coco.json\n"
     ]
    }
   ],
   "source": [
    "# DatasetCatalog.clear()\n",
    "# MetadataCatalog.clear()\n",
    "\n",
    "dataset_name = \"piscinas_train\"\n",
    "# Registrar instancia de COCO\n",
    "register_coco_instances(dataset_name, {}, paths[\"annotations_train\"], paths[\"images_train\"])\n",
    "# Cargar la instancia de COCO como un objeto Dataset\n",
    "dataset = DatasetCatalog.get(dataset_name)\n",
    "# Obtener metadatos del dataset\n",
    "metadata = MetadataCatalog.get(dataset_name)\n",
    "# Declarar el DataLoader\n",
    "data_loader_train = DataLoader(dataset, batch_size=paramaters[\"batch_size\"], collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bbox_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calcula el IoU entre dos cajas delimitadoras en formato [x1, y1, x2, y2]\n",
    "    \"\"\"\n",
    "    # Obtener las coordenadas de la intersección\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "\n",
    "    # Calcular el área de la intersección\n",
    "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "\n",
    "    # Calcular el área de ambas cajas\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\n",
    "    # Calcular el IoU\n",
    "    iou = inter_area / float(box1_area + box2_area - inter_area)\n",
    "\n",
    "    return iou\n",
    "\n",
    "def calculate_bbox_iou(dic_confusion, pred_boxes, true_boxes, threshold):\n",
    "    # indice 0 predicciones\n",
    "    # indice 1 true\n",
    "    n_preds = pred_boxes.shape[0]\n",
    "    n_true = true_boxes.shape[0]\n",
    "    ious = torch.zeros(n_preds, n_true)\n",
    "    for n1 in range(n_preds):\n",
    "        for n2 in range(n_true):\n",
    "            ious[n1, n2] = bbox_iou(pred_boxes[n1, :], true_boxes[n2, :])\n",
    "    true_positives = torch.clamp(torch.sum(ious>threshold, axis=1), 0, 1).sum()\n",
    "    # Calculate true_positives\n",
    "    dic_confusion[\"true_positives\"] += true_positives\n",
    "    # Calculate false_positives\n",
    "    dic_confusion[\"false_positives\"] += n_preds - true_positives\n",
    "    # Calculate false_negatives\n",
    "    dic_confusion[\"false_negatives\"] += n_true - torch.clamp(torch.sum(ious>threshold, axis=0), 0, 1).sum()\n",
    "    \n",
    "def calcular_metricas(model, data_loader, threshold_iou, threshold_preds, show_confusion=False):\n",
    "    model.eval()\n",
    "#     print(\"threshold_preds\", threshold_preds, \"threshold_iou\", threshold_iou)\n",
    "    dic_confusion = {\"true_positives\": 0, \n",
    "                     \"false_positives\": 0,\n",
    "                     \"false_negatives\": 0}\n",
    "#     for images, targets in tqdm(data_loader):\n",
    "#         targets = copy.deepcopy(targets_)\n",
    "    for images, targets in data_loader:\n",
    "        images = [image.to(device) for image in images]\n",
    "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "        output = model(images)\n",
    "        for n in range(len(images)):\n",
    "            pred_boxes = output[\"pred_boxes\"][n].detach()\n",
    "            mask_1d = output[\"pred_logits\"][n]>threshold_preds\n",
    "            mask = torch.cat((mask_1d, mask_1d, mask_1d, mask_1d), 1)\n",
    "            pred_boxes = output[\"pred_boxes\"][n][mask].reshape(-1, 4)\n",
    "            pred_logits = output[\"pred_logits\"][n][mask_1d]\n",
    "            if pred_boxes.shape[0]>0:\n",
    "                pred_boxes = cxcywh_to_xyxy(pred_boxes)\n",
    "                indices = torchvision.ops.nms(pred_boxes, output[\"pred_logits\"][n][mask_1d], 0.5) \n",
    "                pred_boxes = pred_boxes[indices]\n",
    "                true_boxes = xywh_to_xyxy(torch.tensor(targets[n][\"boxes\"]))\n",
    "                calculate_bbox_iou(dic_confusion, pred_boxes, true_boxes, threshold_iou)\n",
    "            else:\n",
    "                print(\"Error\")\n",
    "    if show_confusion:\n",
    "        print(dic_confusion)\n",
    "    \n",
    "    precision = dic_confusion[\"true_positives\"] / (dic_confusion[\"true_positives\"] + dic_confusion[\"false_positives\"])\n",
    "    recall = dic_confusion[\"true_positives\"] / (dic_confusion[\"true_positives\"] + dic_confusion[\"false_negatives\"])\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    print(f\"{threshold_preds} & {precision:.4f} & {recall:.4f} & {f1_score:.4f} \\\\\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5,0.4,0.7067821025848389,0.7199411988258362,0.7133010029792786\n"
     ]
    }
   ],
   "source": [
    "calcular_metricas(model, data_loader_test, threshold_iou = 0.5, threshold_preds = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'true_positives': tensor(7824), 'false_positives': tensor(1029), 'false_negatives': tensor(3731)}\n",
      "0.5,0.4,0.8837682008743286,0.6771094799041748,0.7667580842971802\n"
     ]
    }
   ],
   "source": [
    "calcular_metricas(model, data_loader_test, threshold_iou = 0.5, threshold_preds = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1915/1915 [10:28<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'true_positives': tensor(69791), 'false_positives': tensor(885), 'false_negatives': tensor(2603)}\n",
      "precision tensor(0.9875)\n",
      "recall tensor(0.9640)\n",
      "f1_score tensor(0.9756)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "calcular_metricas(model, data_loader_train, threshold_iou = 0.5, threshold_preds = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [01:18<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'true_positives': tensor(8570), 'false_positives': tensor(118), 'false_negatives': tensor(333)}\n",
      "precision tensor(0.9864)\n",
      "recall tensor(0.9626)\n",
      "f1_score tensor(0.9744)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "calcular_metricas(model, data_loader_validation, threshold_iou = 0.5, threshold_preds = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'true_positives': tensor(6710), 'false_positives': tensor(1911), 'false_negatives': tensor(3343)}\n",
      "0.5,0.75,0.778331995010376,0.6674624681472778,0.7186462879180908\n"
     ]
    }
   ],
   "source": [
    "calcular_metricas(model, data_loader_test, threshold_iou = 0.5, threshold_preds = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'true_positives': tensor(7534), 'false_positives': tensor(934), 'false_negatives': tensor(4015)}\n",
      "0.5,0.7,0.8897023797035217,0.6523508429527283,0.752760112285614\n"
     ]
    }
   ],
   "source": [
    "calcular_metricas(model, data_loader_test, threshold_iou = 0.5, threshold_preds = 0.7, show_confusion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold_iou,threshold_preds,precision,recall,f1_score\n",
      "0.1 & 0.7820 & 0.8099 & 0.7957 \\\\\n",
      "0.2 & 0.8415 & 0.7775 & 0.8083 \\\\\n",
      "0.3 & 0.8701 & 0.7547 & 0.8083 \\\\\n",
      "0.4 & 0.8885 & 0.7366 & 0.8054 \\\\\n",
      "0.5 & 0.9008 & 0.7194 & 0.7999 \\\\\n",
      "0.6 & 0.9121 & 0.7010 & 0.7927 \\\\\n",
      "0.7 & 0.9237 & 0.6779 & 0.7819 \\\\\n",
      "0.8 & 0.9334 & 0.6427 & 0.7612 \\\\\n",
      "0.9 & 0.9505 & 0.5620 & 0.7064 \\\\\n"
     ]
    }
   ],
   "source": [
    "print(\"threshold_iou,threshold_preds,precision,recall,f1_score\")\n",
    "for x in range(1, 10):\n",
    "    calcular_metricas(model, data_loader_test, threshold_iou = 0.5, threshold_preds = x/10) #241"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'true_positives': tensor(9358), 'false_positives': tensor(2608), 'false_negatives': tensor(2196)}\n",
      "0.1 & 0.7820 & 0.8099 & 0.7957 \\\\\n"
     ]
    }
   ],
   "source": [
    "calcular_metricas(model, data_loader_test, threshold_iou = 0.5, threshold_preds = 0.1, show_confusion=True) #241"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold_iou,threshold_preds,precision,recall,f1_score\n",
      "0.5,0.1,0.7152000069618225,0.7738249897956848,0.7433583736419678\n",
      "0.5,0.2,0.780720055103302,0.7453034520149231,0.7626007795333862\n",
      "0.5,0.3,0.8152903318405151,0.7257142663002014,0.7678987979888916\n",
      "0.5,0.4,0.8389076590538025,0.7101298570632935,0.7691659331321716\n",
      "0.5,0.5,0.8585329055786133,0.6952117085456848,0.7682886123657227\n",
      "0.5,0.6,0.8729946613311768,0.6785002946853638,0.7635565996170044\n",
      "0.5,0.7,0.8897023797035217,0.6523508429527283,0.752760112285614\n",
      "0.5,0.8,0.9117533564567566,0.6146518588066101,0.7342885136604309\n",
      "Error\n",
      "0.5,0.9,0.9404378533363342,0.506766140460968,0.6586245894432068\n"
     ]
    }
   ],
   "source": [
    "print(\"threshold_iou,threshold_preds,precision,recall,f1_score\")\n",
    "for x in range(1, 10):\n",
    "    calcular_metricas(model, data_loader_test, threshold_iou = 0.5, threshold_preds = x/10) # 145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas(model, data_loader, threshold_iou, threshold_preds, show_confusion=False):\n",
    "    model.eval()\n",
    "    dic_confusion = {\"true_positives\": 0, \n",
    "                     \"false_positives\": 0,\n",
    "                     \"false_negatives\": 0}\n",
    "    for images, targets in data_loader:\n",
    "        images = [image.to(device) for image in images]\n",
    "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "        output = model(images)\n",
    "        for n in range(len(images)):\n",
    "            pred_boxes = output[\"pred_boxes\"][n].detach()\n",
    "            mask_1d = output[\"pred_logits\"][n]>threshold_preds\n",
    "            mask = torch.cat((mask_1d, mask_1d, mask_1d, mask_1d), 1)\n",
    "            pred_boxes = output[\"pred_boxes\"][n][mask].reshape(-1, 4)\n",
    "            pred_logits = output[\"pred_logits\"][n][mask_1d]\n",
    "            if pred_boxes.shape[0]>0:\n",
    "                pred_boxes = cxcywh_to_xyxy(pred_boxes)\n",
    "                indices = torchvision.ops.nms(pred_boxes, output[\"pred_logits\"][n][mask_1d], 0.5) \n",
    "                pred_boxes = pred_boxes[indices]\n",
    "                true_boxes = xywh_to_xyxy(torch.tensor(targets[n][\"boxes\"]))\n",
    "                calculate_bbox_iou(dic_confusion, pred_boxes, true_boxes, threshold_iou)\n",
    "            else:\n",
    "                print(\"Error\")\n",
    "    if show:\n",
    "        print(dic_confusion)\n",
    "    \n",
    "    roc_curve\n",
    "    \n",
    "    print(f\"{threshold_iou},{threshold_preds},{precision},{recall},{f1_score}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
